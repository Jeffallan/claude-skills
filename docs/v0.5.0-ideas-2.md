# Workflow Commands Overhaul Plan (v0.5.0)

## Overview

Decouple workflow commands from Jira/Confluence, add per-project backend configuration, create a project intake phase, rework discovery for product-centric workflows, integrate feature-forge into the pipeline, and fix the epic creation gap.

**Addresses:** Issues #62, #103, #109 | Discussion #112 | Feature-forge integration | Project intake process

---

## Architecture: Backend Adapter Pattern

Every command gains a Phase 0 config resolution step that loads backend-specific reference files:

```
.claude/workflow-config.json (in consumer project)
    ├── ticketing: "local" | "jira" | "github-issues"
    └── documentation: "local" | "confluence" | "github-wiki"

Command Phase 0:
  1. Read .claude/workflow-config.json (default: local/local)
  2. Load references/ticketing-{backend}.md
  3. Load references/docs-{backend}.md
  4. Proceed with abstract operations
```

All existing commands replace hardcoded Jira/Confluence operations with abstract verbs ("create ticket", "publish document") and a routing table to backend-specific reference files.

---

## Namespace Change

Drop the `project:` prefix from all commands. Use `phase:action` format:

| Old | New |
|-----|-----|
| `project:discovery:create-epic-discovery` | `discovery:create` |
| `project:discovery:synthesize-discovery` | `discovery:synthesize` |
| `project:discovery:approve-synthesis` | `discovery:approve` |
| `project:planning:create-epic-plan` | `planning:epic-plan` |
| `project:planning:create-implementation-plan` | `planning:impl-plan` |
| `project:execution:execute-ticket` | `execution:execute-ticket` |
| `project:execution:complete-ticket` | `execution:complete-ticket` |
| `project:retrospectives:complete-epic` | `retrospectives:complete-epic` |
| `project:retrospectives:complete-sprint` | **REMOVED** |
| *(new)* | `intake:document-codebase` |
| *(new)* | `intake:capture-behavior` |
| *(new)* | `intake:create-system-description` |

---

## Workflow DAG

Different people may own different phases. The workflow is a DAG, not a strict sequence.

```
INTAKE (one-time)                      PRODUCT DISCOVERY (human-driven)
├─ intake:document-codebase            ├─ Value Propositions
├─ intake:capture-behavior             ├─ Customer Segments
└─ intake:create-system-description    ├─ Domain Research
         │                             └─ Feature Identification
         │                                    │
         │                            FEATURE DEFINITION (per feature)
         │                            └─ feature-forge → specs/{name}.spec.md
         │                                    │
         │                            DISCOVERY (when research needed, optional)
         │                            ├─ discovery:create (from topic, NOT from Jira epic)
         │                            ├─ [HUMAN RESEARCH]
         │                            ├─ discovery:synthesize (local docs, notes, artifacts)
         │                            └─ discovery:approve → creates EPICS + tickets
         │                                    │
         └───────────────┬────────────────────┘
                         │
                     PLANNING
                     ├─ planning:epic-plan (stakeholder-readable overview)
                     └─ planning:impl-plan (execution plan + skill-aware tickets)
                         │
                     EXECUTION
                     ├─ execution:execute-ticket × N
                     └─ execution:complete-ticket × N (incremental sys desc updates)
                         │
                     RETROSPECTIVE
                     └─ retrospectives:complete-epic (retro report + sys desc update)
```

**Key relationships:**
- Intake and Product Discovery run in **parallel** (independent)
- Feature-forge specs features BEFORE discovery commands run
- Discovery is **optional** — skip if feature spec is sufficient, use when unknowns need human research
- Discovery creates epics (not consumes them) — this is the #103 fix
- Common-ground runs **on demand** (future hooks per #111)

**Total commands:** 11 (was 9, proposed 13 → reduced to 11)
- 3 new (intake)
- 1 removed (complete-sprint)
- 7 existing (reworked)

---

## Phase 1: Configuration Schema & Backend Adapters

**Goal:** Create the shared reference files that all commands will depend on.

### Files to Create

| File | Purpose | ~Lines |
|------|---------|--------|
| `commands/references/workflow-config-schema.md` | JSON schema for `.claude/workflow-config.json` with examples for each backend combo | 200 |
| `commands/references/config-resolution.md` | How commands resolve config: find file → validate → load backends → fallback to local | 120 |
| `commands/references/ticketing-local.md` | Local markdown tickets: YAML frontmatter + body in `docs/epics/{phase}/{epic}/tickets/` | 150 |
| `commands/references/ticketing-jira.md` | Jira operations via Atlassian MCP; cross-refs `atlassian-mcp` skill | 150 |
| `commands/references/ticketing-github-issues.md` | GitHub Issues via `gh` CLI; labels as status, milestones as epics | 150 |
| `commands/references/docs-local.md` | Local markdown docs in structured `docs/` folder mirroring Confluence paths | 150 |
| `commands/references/docs-confluence.md` | Confluence operations via Atlassian MCP; cross-refs `atlassian-mcp` skill | 150 |
| `commands/references/docs-github-wiki.md` | GitHub Wiki pages via `gh` CLI | 100 |
| `commands/references/local-docs-structure.md` | Full local directory structure with Docusaurus setup guidance | 200 |

**Total:** 9 new files (~1,370 lines)

### Script Fix Required

**File:** `scripts/update-docs.py` (line 84-89)

`count_workflows()` uses `rglob("*.md")` which would count reference files. Fix to exclude `references/` subdirectories:

```python
def count_workflows(base_path: Path) -> int:
    """Count workflow command markdown files."""
    commands_dir = base_path / COMMANDS_DIR
    if not commands_dir.exists():
        return 0
    return sum(1 for f in commands_dir.rglob("*.md") if "references" not in f.parts)
```

---

## Phase 2: Decouple All 9 Existing Commands

**Goal:** Rewrite each command to use abstract operations with routing table.

Each command gets:
1. New Phase 0 step: config resolution (load backend refs)
2. All Jira/Confluence references → abstract operations ("create ticket", "publish document")
3. Routing table at bottom pointing to backend reference files
4. Backend-specific failure conditions generalized

| Command File | Refs to Abstract | Key Changes |
|-------------|-----------------|-------------|
| `discovery/create-epic-discovery.md` | 12 | Fetch epic → "query epic"; Publish to Confluence → "publish document" |
| `discovery/synthesize-discovery.md` | 6 | Source URLs → Source Refs (URLs or local paths); abstract publish |
| `discovery/approve-synthesis.md` | 11 | Create Jira tickets → "create tickets"; Epic Link → "link to epic" |
| `planning/create-epic-plan.md` | 16 | Highest coupling; JQL queries → "query child tickets"; 5 agent refs stay |
| `planning/create-implementation-plan.md` | 9 | Update Jira tickets → "update tickets"; Confluence plan → "publish plan" |
| `execution/execute-ticket.md` | 9 | Fetch Jira ticket → "fetch ticket"; status transitions abstracted |
| `execution/complete-ticket.md` | 12 | Transition Jira → "transition status"; Update Confluence → "update plan" |
| `retrospectives/complete-epic.md` | 11 | Close Jira → "close epic"; move Confluence pages → "move documents" |
| `retrospectives/complete-sprint.md` | 8 | Load Jira data → "load ticket data"; publish retro → "publish document" |

**Total:** 94 hardcoded references abstracted across 9 files

---

## Phase 3: Rework Discovery Commands + Fix Epic Creation (Issues #62, #103)

**Goal:** Reframe discovery from "Jira epic research" to "product discovery support." Discovery starts from a TOPIC (value prop, feature area), not a pre-existing Jira epic. It PRODUCES epics and tickets.

### 3.1 Rework `discovery:create` (was `create-epic-discovery`)

**File:** `commands/discovery/create.md` (renamed + rewritten)

**Key changes:**
- Input: a **topic** (value proposition, feature area, research question) — NOT an epic key
- Accepts local sources: markdown files, PDFs, URLs, meeting notes, feature-forge specs
- Creates a structured discovery workspace (local or in doc system)
- Sections: research questions, hypotheses, unknowns, domain context, stakeholder inputs
- Does NOT require pre-existing Jira/ticketing artifacts

### 3.2 Rework `discovery:synthesize` (was `synthesize-discovery`)

**File:** `commands/discovery/synthesize.md` (renamed + rewritten)

**Key changes:**
- Input: discovery workspace refs, local docs, research artifacts (not just Confluence URLs)
- Consolidates findings into actionable recommendations
- Proposes **epics AND tickets** (not just tickets) with metadata
- Output includes proposed epic structure aligned with value propositions

### 3.3 Rework `discovery:approve` + Fix Epic Creation (was `approve-synthesis`)

**File:** `commands/discovery/approve.md` (renamed + rewritten)

**Key changes:**
- Creates EPICS first, then tickets linked to epics (fixes #103)
- Phase 1.5: Epic Verification & Creation:
  - **A) Auto-create** — present epic details for approval, create in batch, record ID mappings
  - **B) Map to existing** — query candidates, let user map proposed → existing epics
  - **C) Skip** — proceed without epic links (warning)
  - **D) Cancel** — abort for manual fix
- Error handling with rollback on batch failure
- Works with any configured ticketing backend (local, Jira, GitHub)

---

## Phase 4: Project Intake Commands (NEW)

**Goal:** 3 new commands under `commands/intake/` for codebase onboarding.

### 4.1 `commands/intake/document-codebase.md` (~250 lines)

```yaml
description: Use when onboarding a new project to add documentation to existing code
argument-hint: [--scope=<path>] [--format=<jsdoc|docstring|xml>]
```

**Workflow:** Scan codebase → identify undocumented functions/classes/modules → prioritize (public APIs first) → checkpoint approval → generate docstrings → output summary → pointer to `capture-behavior`

### 4.2 `commands/intake/capture-behavior.md` (~250 lines)

```yaml
description: Use when capturing existing system behavior through tests for an undocumented codebase
argument-hint: [--scope=<path>] [--type=<unit|integration|both>]
```

**Workflow:** Scan code → identify untested behavior → analyze coverage gaps → checkpoint test plan → generate characterization tests (assert CURRENT behavior) → run tests → output summary → pointer to `create-system-description`

### 4.3 `commands/intake/create-system-description.md` (~300 lines)

```yaml
description: Use when creating a living system description document for a project
argument-hint: [--output=<path>]
```

**Workflow:** Parallel agent analysis (architecture, security, API, data) → generate SOC2-style document with sections:
- System Purpose & Scope
- System Components (services, databases, queues, caches)
- Data Flow Diagram (mermaid)
- Security Architecture
- API Surface Area
- External Dependencies
- Infrastructure Overview
- Change Management Process

**Output:** `docs/system-description.md` (configurable path)

### 4.4 Intake Reference Files

| File | Purpose | ~Lines |
|------|---------|--------|
| `commands/intake/references/characterization-tests.md` | Patterns for behavior-capturing tests across languages | 200 |
| `commands/intake/references/system-description-template.md` | Full SOC2-style template with examples for web apps, APIs, microservices | 300 |

**Total Phase 4:** 5 new files (~1,300 lines)

---

## Phase 5: Feature-Forge Integration & System Description Updates

### 5.1 Feature-Forge Reads System Description

**File:** `skills/feature-forge/SKILL.md`

Add Step 0 to Core Workflow:
> 0. **Context** — Check for `docs/system-description.md` (or path from config). If found, load as background context. Reference existing components/APIs during interviews. Skip questions the system description already answers.

**New file:** `skills/feature-forge/references/system-context-integration.md` (~150 lines)
- How to use system description sections during requirements gathering
- Which sections inform which interview questions
- How specs should reference system components

### 5.2 Clarify Feature-Forge Output Boundaries

**File:** `skills/feature-forge/references/specification-template.md`

Changes:
- Add `## Workflow Integration` section with epic target field and explicit note: "High-level TODOs only. Detailed implementation steps generated by `/planning:impl-plan`."
- Make EARS format **optional** — offer EARS for complex features with conditional/state-dependent behavior; simpler formats for straightforward features. Let feature-forge choose based on feature complexity or user preference.
- This eliminates the duplicate implementation checklist problem

### 5.3 Feature-Forge Discovery Integration

**File:** `skills/feature-forge/SKILL.md`

During the structured interview, every `AskUserQuestions` prompt about proposed functionality includes a standing option: **"Needs additional discovery"** (or contextual variant like "Unknown — needs research"). This gives users a consistent way to flag unknowns in real-time rather than trying to answer questions they don't have data for.

When the user selects this option, feature-forge:
1. Records the question topic as a flagged unknown
2. Moves to the next question without blocking

At the end of the interview, if any unknowns were flagged, feature-forge:
1. Adds a `## Discovery Recommendation` section to the spec listing the specific unknowns with their original question context
2. Presents an `AskUserQuestions` prompt:

```
Question: "This feature has N open questions flagged for discovery.
           How would you like to proceed?"

Options:
  A) "Run discovery (Recommended)"
     — Create a discovery workspace to research the unknowns
       identified above before planning
  B) "Skip to planning"
     — Proceed directly to planning with current assumptions.
       Unknowns will be flagged as risks in the spec
  C) "I'll handle research separately"
     — Mark unknowns for manual research.
       Run discovery:create later when ready
```

If no unknowns were flagged during the interview, no discovery recommendation is shown. Users can always invoke `discovery:create` manually regardless.

**File updates:**
- `skills/feature-forge/SKILL.md` — Add "Needs additional discovery" as standing AskUserQuestions option during interview, add post-interview discovery recommendation flow
- `skills/feature-forge/references/system-context-integration.md` — Include guidance on how flagged unknowns map to discovery workspace research questions

### 5.4 `planning:epic-plan` Reads Feature Specs

**File:** `commands/planning/epic-plan.md` (renamed from `commands/project/planning/create-epic-plan.md`)

Add to Phase 0:
> Check for `specs/{feature_name}.spec.md` related to this epic. If found, use requirements, acceptance criteria, and NFRs as input. Do not re-derive what the spec already defines.

### 5.5 `planning:impl-plan` Skill-Aware Ticket Creation

**File:** `commands/planning/impl-plan.md` (renamed from `commands/project/planning/create-implementation-plan.md`)

Enhancement: When generating self-contained ticket descriptions, read available skills at the project level (`.claude-plugin/plugin.json` or installed skill manifests) and craft prompts in ticket descriptions that invoke the correct skill for each implementation step.

Example ticket description might include:
> **Suggested skill:** `react-expert` for component implementation, `test-master` for test suite

### 5.6 System Description Updates on Completion

**File:** `commands/execution/complete-ticket.md` — Add Step 4c:
> Check for system description. If changes affect APIs, external deps, security, or data models → propose targeted updates → checkpoint approval → apply. This ensures incremental updates rather than bulk changes.

**File:** `commands/retrospectives/complete-epic.md` — Add to Phase 5:
> Review all changes across the epic. Update system description to reflect new system state. Update mermaid diagrams if architecture changed. Checkpoint approval.

---

## Phase 6: Directory Restructure

**Goal:** Rename `commands/project/` subdirectories to drop the `project/` nesting and match new namespace.

| Old Path | New Path | Notes |
|----------|----------|-------|
| `commands/project/discovery/` | `commands/discovery/` | Renamed files inside (see Phase 3) |
| `commands/project/planning/` | `commands/planning/` | Renamed files inside |
| `commands/project/execution/` | `commands/execution/` | Files keep same names |
| `commands/project/retrospectives/` | `commands/retrospectives/` | Remove `complete-sprint.md` |
| `commands/references/` | `commands/references/` | Shared adapter refs (Phase 1) |
| *(new)* | `commands/intake/` | New intake commands (Phase 4) |

**File renames within directories:**

| Old Filename | New Filename |
|-------------|-------------|
| `create-epic-discovery.md` | `create.md` |
| `synthesize-discovery.md` | `synthesize.md` |
| `approve-synthesis.md` | `approve.md` |
| `create-epic-plan.md` | `epic-plan.md` |
| `create-implementation-plan.md` | `impl-plan.md` |
| `complete-sprint.md` | **DELETED** |

**Script update required:** `scripts/update-docs.py` line 40 — change `COMMANDS_DIR = "commands/project"` to `COMMANDS_DIR = "commands"` and ensure `count_workflows()` excludes `references/` dirs and `common-ground/`.

**Plugin config update:** `.claude-plugin/plugin.json` — update command directory references and registered command names.

---

## Phase 7: Documentation & Release

| File | Changes |
|------|---------|
| `docs/WORKFLOW_COMMANDS.md` | Major rewrite: new namespace, DAG lifecycle, Configuration section, Intake Phase, discovery rework, all backends, feature-forge integration, skill-aware tickets, command table (11 commands) |
| `SKILLS_GUIDE.md` | Add feature-forge workflow integration notes |
| `README.md` | Update workflow section; note Atlassian MCP is now optional; add `.claude/workflow-config.json` reference; update directory structure |
| `ROADMAP.md` | Update #62, #103 status; add intake phase items |
| `CHANGELOG.md` | Add v0.5.0 entry |
| `docs/ATLASSIAN_MCP_SETUP.md` | Add note: only needed when config specifies jira/confluence backends |
| `version.json` | Bump to `0.5.0` |
| `.claude-plugin/plugin.json` | Update command paths, names, keywords (add "local-first", "github-issues", "workflow-config") |

---

## Phase 8: Validation

1. `python scripts/validate-skills.py` — all skill YAML valid
2. `python scripts/update-docs.py --check` — counts in sync (should show 11 workflows)
3. Verify no hardcoded Jira/Confluence refs in command files (only in `references/` backend files):
   ```
   grep -r "Jira\|Confluence\|JQL\|Atlassian" commands/discovery/ commands/planning/ commands/execution/ commands/retrospectives/ commands/intake/
   ```
4. Verify all new files have valid frontmatter
5. Verify reference files are within 100-600 line range
6. Verify `complete-sprint.md` is deleted, no dangling references
7. `python scripts/update-docs.py` — propagate final counts
8. `node ./assets/capture-screenshot.js` — regenerate social preview

---

## File Manifest

### New Files (15 files, ~2,970 lines)

| Phase | File | ~Lines |
|-------|------|--------|
| 1 | `commands/references/workflow-config-schema.md` | 200 |
| 1 | `commands/references/config-resolution.md` | 120 |
| 1 | `commands/references/ticketing-local.md` | 150 |
| 1 | `commands/references/ticketing-jira.md` | 150 |
| 1 | `commands/references/ticketing-github-issues.md` | 150 |
| 1 | `commands/references/docs-local.md` | 150 |
| 1 | `commands/references/docs-confluence.md` | 150 |
| 1 | `commands/references/docs-github-wiki.md` | 100 |
| 1 | `commands/references/local-docs-structure.md` | 200 |
| 4 | `commands/intake/document-codebase.md` | 250 |
| 4 | `commands/intake/capture-behavior.md` | 250 |
| 4 | `commands/intake/create-system-description.md` | 300 |
| 4 | `commands/intake/references/characterization-tests.md` | 200 |
| 4 | `commands/intake/references/system-description-template.md` | 300 |
| 5 | `skills/feature-forge/references/system-context-integration.md` | 150 |

### Renamed/Moved Files (restructure in Phase 6)

| Old Path | New Path |
|----------|----------|
| `commands/project/discovery/create-epic-discovery.md` | `commands/discovery/create.md` |
| `commands/project/discovery/synthesize-discovery.md` | `commands/discovery/synthesize.md` |
| `commands/project/discovery/approve-synthesis.md` | `commands/discovery/approve.md` |
| `commands/project/planning/create-epic-plan.md` | `commands/planning/epic-plan.md` |
| `commands/project/planning/create-implementation-plan.md` | `commands/planning/impl-plan.md` |
| `commands/project/execution/execute-ticket.md` | `commands/execution/execute-ticket.md` |
| `commands/project/execution/complete-ticket.md` | `commands/execution/complete-ticket.md` |
| `commands/project/retrospectives/complete-epic.md` | `commands/retrospectives/complete-epic.md` |

### Deleted Files

| File | Reason |
|------|--------|
| `commands/project/retrospectives/complete-sprint.md` | Sprint retrospectives removed; retros at epic level only |

### Modified Files (not counting renames)

| Phase | File | Change Scope |
|-------|------|-------------|
| 1+6 | `scripts/update-docs.py` | Fix `count_workflows()`, update `COMMANDS_DIR` |
| 2+3 | `commands/discovery/create.md` | Full rewrite: topic-based, not Jira-epic-based |
| 2+3 | `commands/discovery/synthesize.md` | Rewrite: local-first input, proposes epics + tickets |
| 2+3 | `commands/discovery/approve.md` | Rewrite: creates epics + tickets, Phase 1.5 epic creation |
| 2+5 | `commands/planning/epic-plan.md` | Abstract refs + read feature specs |
| 2+5 | `commands/planning/impl-plan.md` | Abstract refs + skill-aware ticket creation |
| 2 | `commands/execution/execute-ticket.md` | Abstract 9 refs |
| 2+5 | `commands/execution/complete-ticket.md` | Abstract 12 refs + system desc update |
| 2+5 | `commands/retrospectives/complete-epic.md` | Abstract 11 refs + system desc update |
| 5 | `skills/feature-forge/SKILL.md` | Add system description context step + discovery integration (standing "Needs additional discovery" option in interview) |
| 5 | `skills/feature-forge/references/specification-template.md` | Workflow integration + optional EARS |
| 7 | `docs/WORKFLOW_COMMANDS.md` | Major rewrite |
| 7 | `SKILLS_GUIDE.md` | Feature-forge integration notes |
| 7 | `README.md` | Update workflow section + directory structure |
| 7 | `ROADMAP.md` | Update issue statuses |
| 7 | `CHANGELOG.md` | Add v0.5.0 entry |
| 7 | `docs/ATLASSIAN_MCP_SETUP.md` | Mark as optional |
| 7 | `version.json` | Bump to 0.5.0 |
| 7 | `.claude-plugin/plugin.json` | Update paths, names, keywords |

### Dependency Order

```
Phase 1 (adapters) → Phase 2 (decouple commands) → Phase 3 (discovery rework + epic fix)
Phase 1 (adapters) → Phase 4 (intake, needs config schema)
Phase 4 (intake)   → Phase 5 (feature-forge, needs system description to exist)
All above          → Phase 6 (directory restructure)
Phase 6            → Phase 7 (docs) → Phase 8 (validation)
```

Phases 2-4 can partially overlap since Phase 4 only depends on Phase 1 (not Phase 2).

---

## Resolved Decisions

- **Epic terminology** — Evaluated alternatives (initiative, feature, workstream, deliverable, milestone). Decision: **keep "epic."** It's the least ambiguous term across all three backends (Jira uses it natively, GitHub Issues maps milestones to it, local markdown uses folder labels). The adapter layer abstracts backend-specific mapping. "Epic" in our commands means "encapsulated body of work" regardless of backend representation.
- **Discovery trigger** — Feature-forge embeds "Needs additional discovery" as a standing option during its structured interview. Flagged unknowns are collected and surfaced as a discovery recommendation at interview end, with options to run discovery, skip to planning, or handle research separately.

## Open Questions for Future Iterations

- **Common-ground hooks** (#111, #107) — on-demand for now; hook-based injection in future
- **Docusaurus setup** — per-project CI/CD concern; add setup instructions in `local-docs-structure.md` but don't implement deployment in this version
- **EARS format** — made optional in feature-forge; monitor whether structured vs. simple format affects agent execution quality
- **Tiki integration** — potential future adapter for the ticketing backend (Go CLI for local task management)
