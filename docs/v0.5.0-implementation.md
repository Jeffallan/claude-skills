# v0.5.0 Implementation Chunks

How to execute the v0.5.0 overhaul in manageable steps. Each chunk is independently verifiable.

**Strategy:** Hybrid restructure — new files created at final paths, existing files rewritten in place, directory moves at the end.

---

## Dependency Graph

```
Chunk 1 (foundation)
├──→ Chunk 2 (decouple non-discovery)──┐
├──→ Chunk 3 (discovery rework)────────┼──→ Chunk 5 (feature-forge)──→ Chunk 6 (restructure)──→ Chunk 7 (docs)
└──→ Chunk 4 (intake)──────────────────┘
```

Chunks 2, 3, and 4 are independent of each other — only Chunk 1 gates them. They can run in parallel if desired.

---

## Chunk 1: Backend Adapter Foundation

**Phase:** 1 | **Depends on:** Nothing

| What | Detail |
|------|--------|
| Create | 9 reference files at `commands/references/` (final path) |
| Fix | `scripts/update-docs.py` — exclude `references/` from workflow count |
| Scope | ~1,370 lines new + small script edit |

### Files to Create

| File | Purpose | ~Lines |
|------|---------|--------|
| `commands/references/workflow-config-schema.md` | JSON schema for `.claude/workflow-config.json` with examples for each backend combo | 200 |
| `commands/references/config-resolution.md` | How commands resolve config: find file → validate → load backends → fallback to local | 120 |
| `commands/references/ticketing-local.md` | Local markdown tickets: YAML frontmatter + body in `docs/epics/{phase}/{epic}/tickets/` | 150 |
| `commands/references/ticketing-jira.md` | Jira operations via Atlassian MCP; cross-refs `atlassian-mcp` skill | 150 |
| `commands/references/ticketing-github-issues.md` | GitHub Issues via `gh` CLI; labels as status, milestones as epics | 150 |
| `commands/references/docs-local.md` | Local markdown docs in structured `docs/` folder mirroring Confluence paths | 150 |
| `commands/references/docs-confluence.md` | Confluence operations via Atlassian MCP; cross-refs `atlassian-mcp` skill | 150 |
| `commands/references/docs-github-wiki.md` | GitHub Wiki pages via `gh` CLI | 100 |
| `commands/references/local-docs-structure.md` | Full local directory structure with Docusaurus setup guidance | 200 |

### Script Fix

**File:** `scripts/update-docs.py` (line 84-89)

`count_workflows()` uses `rglob("*.md")` which would count reference files. Fix to exclude `references/` subdirectories:

```python
def count_workflows(base_path: Path) -> int:
    """Count workflow command markdown files."""
    commands_dir = base_path / COMMANDS_DIR
    if not commands_dir.exists():
        return 0
    return sum(1 for f in commands_dir.rglob("*.md") if "references" not in f.parts)
```

### Verification

```bash
python scripts/update-docs.py --check
# Should still report 9 workflows (refs not counted)
```

---

## Chunk 2: Decouple Non-Discovery Commands

**Phase:** 2 (partial) | **Depends on:** Chunk 1

| What | Detail |
|------|--------|
| Rewrite in place | 5 existing commands — abstract Jira/Confluence operations |
| Skip | `complete-sprint.md` — being deleted, no point decoupling |
| Per-file changes | Add Phase 0 config resolution, abstract all hardcoded operations, add routing table |
| Scope | 5 files, ~57 references abstracted |

### Commands to Decouple

| Command File | Refs to Abstract | Key Changes |
|-------------|-----------------|-------------|
| `commands/project/planning/create-epic-plan.md` | 16 | JQL queries → "query child tickets"; 5 agent refs stay |
| `commands/project/planning/create-implementation-plan.md` | 9 | Update Jira tickets → "update tickets"; Confluence plan → "publish plan" |
| `commands/project/execution/execute-ticket.md` | 9 | Fetch Jira ticket → "fetch ticket"; status transitions abstracted |
| `commands/project/execution/complete-ticket.md` | 12 | Transition Jira → "transition status"; Update Confluence → "update plan" |
| `commands/project/retrospectives/complete-epic.md` | 11 | Close Jira → "close epic"; move Confluence pages → "move documents" |

Each command gets:
1. **Phase 0** — Config resolution step (load backend refs)
2. **Abstract operations** — All Jira/Confluence verbs replaced with generic verbs
3. **Routing table** — Footer section pointing to backend-specific reference files

### Verification

```bash
# No hardcoded Jira/Confluence refs outside routing tables
grep -r "Jira\|Confluence\|JQL" commands/project/planning/ commands/project/execution/ commands/project/retrospectives/
# Should only appear in routing table comments, not in operational steps
```

---

## Chunk 3: Discovery Rework

**Phase:** 2+3 (merged) | **Depends on:** Chunk 1

| What | Detail |
|------|--------|
| Full rewrite | 3 discovery commands in place |
| Key changes | Topic-based input (not Jira epic key), local-first sources, produces epics AND tickets, Phase 1.5 epic creation (#103 fix) |
| Scope | 3 files, full rewrites (~750 lines total) |

Merges Phase 2 decoupling with Phase 3 rework — no point abstracting refs in files getting fully rewritten.

### 3.1 `create-epic-discovery.md` → topic-based discovery

**Current:** Takes a Jira epic key, fetches epic details, creates Confluence discovery page.

**New:** Takes a **topic** (value proposition, feature area, research question). Accepts local sources: markdown files, PDFs, URLs, meeting notes, feature-forge specs. Creates a structured discovery workspace (local or in doc system) with research questions, hypotheses, unknowns, domain context, stakeholder inputs. Does NOT require pre-existing ticketing artifacts.

### 3.2 `synthesize-discovery.md` → local-first synthesis

**Current:** Takes Confluence URLs as input, publishes synthesis to Confluence.

**New:** Takes discovery workspace refs, local docs, research artifacts (not just Confluence URLs). Consolidates findings into actionable recommendations. Proposes **epics AND tickets** (not just tickets) with metadata. Output includes proposed epic structure aligned with value propositions.

### 3.3 `approve-synthesis.md` → epic creation fix (#103)

**Current:** Assumes target epics exist in Jira. Creates tickets linked to existing epics.

**New:** Creates EPICS first, then tickets linked to epics. Adds Phase 1.5: Epic Verification & Creation:
- **A) Auto-create** — present epic details for approval, create in batch, record ID mappings
- **B) Map to existing** — query candidates, let user map proposed → existing epics
- **C) Skip** — proceed without epic links (warning)
- **D) Cancel** — abort for manual fix

Error handling with rollback on batch failure. Works with any configured ticketing backend.

### Verification

```bash
# No hardcoded Jira/Confluence refs outside routing tables
grep -r "Jira\|Confluence\|JQL" commands/project/discovery/
# approve-synthesis.md contains Phase 1.5 epic creation flow
grep -c "Epic Verification" commands/project/discovery/approve-synthesis.md
```

---

## Chunk 4: Intake Commands

**Phase:** 4 | **Depends on:** Chunk 1

| What | Detail |
|------|--------|
| Create at final paths | 3 new commands under `commands/intake/` |
| Create refs | 2 reference files under `commands/intake/references/` |
| Scope | 5 new files (~1,300 lines) |

Independent of Chunks 2 and 3 — only needs Chunk 1.

### 4.1 `commands/intake/document-codebase.md` (~250 lines)

```yaml
description: Use when onboarding a new project to add documentation to existing code
argument-hint: [--scope=<path>] [--format=<jsdoc|docstring|xml>]
```

**Workflow:** Scan codebase → identify undocumented functions/classes/modules → prioritize (public APIs first) → checkpoint approval → generate docstrings → output summary → pointer to `capture-behavior`

### 4.2 `commands/intake/capture-behavior.md` (~250 lines)

```yaml
description: Use when capturing existing system behavior through tests for an undocumented codebase
argument-hint: [--scope=<path>] [--type=<unit|integration|both>]
```

**Workflow:** Scan code → identify untested behavior → analyze coverage gaps → checkpoint test plan → generate characterization tests (assert CURRENT behavior) → run tests → output summary → pointer to `create-system-description`

### 4.3 `commands/intake/create-system-description.md` (~300 lines)

```yaml
description: Use when creating a living system description document for a project
argument-hint: [--output=<path>]
```

**Workflow:** Parallel agent analysis (architecture, security, API, data) → generate SOC2-style document:
- System Purpose & Scope
- System Components (services, databases, queues, caches)
- Data Flow Diagram (mermaid)
- Security Architecture
- API Surface Area
- External Dependencies
- Infrastructure Overview
- Change Management Process

**Output:** `docs/system-description.md` (configurable path)

### 4.4 Reference Files

| File | Purpose | ~Lines |
|------|---------|--------|
| `commands/intake/references/characterization-tests.md` | Patterns for behavior-capturing tests across languages | 200 |
| `commands/intake/references/system-description-template.md` | Full SOC2-style template with examples for web apps, APIs, microservices | 300 |

### Verification

```bash
# All files have valid frontmatter
head -5 commands/intake/*.md
# Reference files within 100-600 line range
wc -l commands/intake/references/*.md
```

---

## Chunk 5: Feature-Forge Integration

**Phase:** 5 | **Depends on:** Chunks 2, 3, and 4

| What | Detail |
|------|--------|
| Update | `skills/feature-forge/SKILL.md` — system description context + discovery integration |
| Update | `skills/feature-forge/references/specification-template.md` — workflow integration + optional EARS |
| Create | `skills/feature-forge/references/system-context-integration.md` (~150 lines) |
| Update | Planning commands — read feature specs, skill-aware ticket descriptions |
| Update | `complete-ticket.md` — incremental system description updates |
| Update | `complete-epic.md` — holistic system description review |
| Scope | 1 new file + 6 files updated |

### 5.1 Feature-Forge: System Description Context

**File:** `skills/feature-forge/SKILL.md`

Add Step 0 to Core Workflow:
> 0. **Context** — Check for `docs/system-description.md` (or path from config). If found, load as background context. Reference existing components/APIs during interviews. Skip questions the system description already answers.

### 5.2 Feature-Forge: Output Boundaries

**File:** `skills/feature-forge/references/specification-template.md`

- Add `## Workflow Integration` section with epic target field
- Explicit note: "High-level TODOs only. Detailed implementation steps generated by `/planning:impl-plan`."
- Make EARS format **optional** — offer for complex features, simpler format for straightforward ones

### 5.3 Feature-Forge: Discovery Integration

**File:** `skills/feature-forge/SKILL.md`

During the structured interview, every `AskUserQuestions` prompt about proposed functionality includes a standing option: **"Needs additional discovery."** When selected, feature-forge records the question topic as a flagged unknown and moves to the next question without blocking.

At interview end, if any unknowns were flagged:
1. Adds `## Discovery Recommendation` section to spec listing unknowns with original question context
2. Presents `AskUserQuestions` prompt:
   - **A) Run discovery (Recommended)** — create discovery workspace for flagged unknowns
   - **B) Skip to planning** — proceed with unknowns flagged as risks
   - **C) Handle research separately** — run `discovery:create` later

If no unknowns flagged, no recommendation shown.

### 5.4 System Context Reference

**New file:** `skills/feature-forge/references/system-context-integration.md` (~150 lines)
- How to use system description sections during requirements gathering
- Which sections inform which interview questions
- How specs should reference system components
- How flagged unknowns map to discovery workspace research questions

### 5.5 Planning Commands: Read Feature Specs

**File:** `commands/project/planning/create-epic-plan.md`

Add to Phase 0:
> Check for `specs/{feature_name}.spec.md` related to this epic. If found, use requirements, acceptance criteria, and NFRs as input. Do not re-derive what the spec already defines.

### 5.6 Planning Commands: Skill-Aware Ticket Creation

**File:** `commands/project/planning/create-implementation-plan.md`

When generating self-contained ticket descriptions, read available skills at the project level (`.claude-plugin/plugin.json` or installed skill manifests) and craft prompts that invoke the correct skill per implementation step.

Example ticket description:
> **Suggested skill:** `react-expert` for component implementation, `test-master` for test suite

### 5.7 System Description Updates on Completion

**File:** `commands/project/execution/complete-ticket.md` — Add Step 4c:
> If changes affect APIs, external deps, security, or data models → propose targeted updates to `docs/system-description.md` → checkpoint approval → apply.

**File:** `commands/project/retrospectives/complete-epic.md` — Add to Phase 5:
> Review all changes across the epic. Update system description holistically. Update mermaid diagrams if architecture changed. Checkpoint approval.

### Verification

```bash
python scripts/validate-skills.py --skill feature-forge
# Verify discovery integration
grep -c "additional discovery" skills/feature-forge/SKILL.md
# Verify spec reading in planning
grep -c "spec.md" commands/project/planning/create-epic-plan.md
```

---

## Chunk 6: Directory Restructure + Cleanup

**Phase:** 6 | **Depends on:** Chunks 1-5 (all content finalized)

| What | Detail |
|------|--------|
| Move | 4 directories from `commands/project/` to `commands/` |
| Rename | 5 files to shorter names |
| Delete | `complete-sprint.md` |
| Update | `scripts/update-docs.py` — `COMMANDS_DIR` path + exclusions |
| Update | `.claude-plugin/plugin.json` — command paths and registered names |
| Scope | Mechanical moves/renames + 2 config updates |

### Directory Moves

| Old Path | New Path |
|----------|----------|
| `commands/project/discovery/` | `commands/discovery/` |
| `commands/project/planning/` | `commands/planning/` |
| `commands/project/execution/` | `commands/execution/` |
| `commands/project/retrospectives/` | `commands/retrospectives/` |

### File Renames

| Old Filename | New Filename |
|-------------|-------------|
| `create-epic-discovery.md` | `create.md` |
| `synthesize-discovery.md` | `synthesize.md` |
| `approve-synthesis.md` | `approve.md` |
| `create-epic-plan.md` | `epic-plan.md` |
| `create-implementation-plan.md` | `impl-plan.md` |

### Deletions

| File | Reason |
|------|--------|
| `commands/project/retrospectives/complete-sprint.md` | Sprint retrospectives removed; retros at epic level only |

### Script Update

**File:** `scripts/update-docs.py`

```python
COMMANDS_DIR = "commands"  # was "commands/project"

def count_workflows(base_path: Path) -> int:
    """Count workflow command markdown files."""
    commands_dir = base_path / COMMANDS_DIR
    if not commands_dir.exists():
        return 0
    return sum(
        1 for f in commands_dir.rglob("*.md")
        if "references" not in f.parts and "common-ground" not in f.parts
    )
```

### Verification

```bash
# Old directory should be empty/gone
ls commands/project/ 2>&1
# Should show: No such file or directory

# Workflow count should be 11
python scripts/update-docs.py --dry-run

# No dangling references to old paths
grep -r "commands/project" commands/ scripts/ .claude-plugin/

# No references to complete-sprint
grep -r "complete-sprint" commands/ docs/ README.md
```

---

## Chunk 7: Documentation + Validation

**Phase:** 7+8 | **Depends on:** Chunk 6

| What | Detail |
|------|--------|
| Major rewrite | `docs/WORKFLOW_COMMANDS.md` |
| Update | `README.md`, `SKILLS_GUIDE.md`, `ROADMAP.md`, `CHANGELOG.md`, `docs/ATLASSIAN_MCP_SETUP.md` |
| Bump | `version.json` → `0.5.0` |
| Propagate | `python scripts/update-docs.py` |
| Validate | Full validation suite |
| Regenerate | Social preview image |

### Documentation Updates

| File | Changes |
|------|---------|
| `docs/WORKFLOW_COMMANDS.md` | Major rewrite: new namespace (`phase:action`), DAG lifecycle diagram, Configuration section, Intake Phase, discovery rework (topic-based), all backends, feature-forge integration, skill-aware tickets, command table (11 commands) |
| `SKILLS_GUIDE.md` | Add feature-forge workflow integration notes (system description context, discovery recommendation, output boundaries) |
| `README.md` | Update workflow section; note Atlassian MCP is now optional; add `.claude/workflow-config.json` reference; update directory structure |
| `ROADMAP.md` | Update #62, #103 status to completed; add intake phase items; update v0.5.0 section |
| `CHANGELOG.md` | Add v0.5.0 entry (Added: intake commands, backend adapters, discovery rework, feature-forge integration; Changed: namespace, directory structure; Removed: complete-sprint; Fixed: #103 epic creation) |
| `docs/ATLASSIAN_MCP_SETUP.md` | Add note: only needed when config specifies jira/confluence backends |
| `version.json` | Bump to `0.5.0` |
| `.claude-plugin/plugin.json` | Update keywords (add "local-first", "github-issues", "workflow-config") |

### Validation Suite

```bash
# 1. Skill validation
python scripts/validate-skills.py

# 2. Doc counts in sync (should show 11 workflows)
python scripts/update-docs.py --check

# 3. No hardcoded Jira/Confluence refs in command files
grep -r "Jira\|Confluence\|JQL\|Atlassian" \
  commands/discovery/ commands/planning/ commands/execution/ \
  commands/retrospectives/ commands/intake/
# Should return nothing (only allowed in commands/references/)

# 4. All new files have valid frontmatter
python scripts/validate-skills.py

# 5. Reference files within 100-600 line range
find commands/ -path "*/references/*.md" -exec wc -l {} \;

# 6. No dangling references to deleted file
grep -r "complete-sprint" commands/ docs/ README.md SKILLS_GUIDE.md

# 7. Propagate final counts
python scripts/update-docs.py

# 8. Regenerate social preview
node ./assets/capture-screenshot.js
```

---

## Summary

| Chunk | Phase | New Files | Modified Files | Lines (est.) |
|-------|-------|-----------|---------------|-------------|
| 1. Backend adapters | 1 | 9 | 1 | ~1,400 |
| 2. Decouple commands | 2 | 0 | 5 | ~500 |
| 3. Discovery rework | 2+3 | 0 | 3 | ~750 |
| 4. Intake commands | 4 | 5 | 0 | ~1,300 |
| 5. Feature-forge | 5 | 1 | 6 | ~600 |
| 6. Restructure | 6 | 0 | 2 + moves | ~100 |
| 7. Docs + validation | 7+8 | 0 | 8 | ~1,500 |
| **Total** | | **15** | **25 + moves** | **~6,150** |

Chunks 2, 3, and 4 can run in parallel after Chunk 1 completes.
